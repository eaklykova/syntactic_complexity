{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3c57e0",
   "metadata": {},
   "source": [
    "# Complexity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f63d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from statistics import mean, median, StatisticsError\n",
    "from itertools import combinations\n",
    "from operator import mul\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from textdistance import levenshtein\n",
    "\n",
    "import conllu\n",
    "from conllu import parse, parse_tree\n",
    "from conllu.exceptions import ParseException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bd01f",
   "metadata": {},
   "source": [
    "## Load annotated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e5ebfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49397, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Елизавета Клыкова\\AppData\\Local\\Temp\\ipykernel_7560\\1388934742.py:1: DtypeWarning: Columns (1,4,5,9,10,14,16,17,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('SyntCompCorpus.tsv', sep='\\t')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>language</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>dialect</th>\n",
       "      <th>language_background</th>\n",
       "      <th>text</th>\n",
       "      <th>spell_checked</th>\n",
       "      <th>annotated</th>\n",
       "      <th>error_annotation</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>L1</th>\n",
       "      <th>level</th>\n",
       "      <th>institution</th>\n",
       "      <th>programme</th>\n",
       "      <th>study_year</th>\n",
       "      <th>term</th>\n",
       "      <th>module</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>russian</td>\n",
       "      <td>L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Прокатившись по многим городам и странам за по...</td>\n",
       "      <td>Прокатившись по многим городам и странам за по...</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heritage 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>russian</td>\n",
       "      <td>L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>В моей жизни я встречала много разных людей. У...</td>\n",
       "      <td>В моей жизни я встречала много разных людей. У...</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heritage 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>russian</td>\n",
       "      <td>L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>В прошлем году, я провела четыре месяцев в Лон...</td>\n",
       "      <td>В прошлом году, я провела четыре месяцев в Лон...</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heritage 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus subcorpus language speaker_type dialect language_background  \\\n",
       "0   actr       NaN  russian           L1     NaN                 NaN   \n",
       "1   actr       NaN  russian           L1     NaN                 NaN   \n",
       "2   actr       NaN  russian           L1     NaN                 NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0  Прокатившись по многим городам и странам за по...   \n",
       "1  В моей жизни я встречала много разных людей. У...   \n",
       "2  В прошлем году, я провела четыре месяцев в Лон...   \n",
       "\n",
       "                                       spell_checked  \\\n",
       "0  Прокатившись по многим городам и странам за по...   \n",
       "1  В моей жизни я встречала много разных людей. У...   \n",
       "2  В прошлом году, я провела четыре месяцев в Лон...   \n",
       "\n",
       "                                           annotated error_annotation  ...  \\\n",
       "0  # generator = UDPipe 2, https://lindat.mff.cun...              NaN  ...   \n",
       "1  # generator = UDPipe 2, https://lindat.mff.cun...              NaN  ...   \n",
       "2  # generator = UDPipe 2, https://lindat.mff.cun...              NaN  ...   \n",
       "\n",
       "  gender  age   L1       level institution programme study_year term module  \\\n",
       "0    NaN  NaN  NaN  Heritage 1         NaN       NaN        NaN  NaN    NaN   \n",
       "1    NaN  NaN  NaN  Heritage 1         NaN       NaN        NaN  NaN    NaN   \n",
       "2    NaN  NaN  NaN  Heritage 1         NaN       NaN        NaN  NaN    NaN   \n",
       "\n",
       "  week  \n",
       "0  NaN  \n",
       "1  NaN  \n",
       "2  NaN  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SyntCompCorpus.tsv', sep='\\t')\n",
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeaf065",
   "metadata": {},
   "source": [
    "## Clause/T-unit extraction\n",
    "\n",
    "### Clauses\n",
    "* root: root of the sentence\n",
    "* acl: clausal modifier of a noun (adnominal clause)\n",
    "* acl:relcl: relative clause modifier\n",
    "* advcl: adverbial clause modifier\n",
    "* advcl:relcl: adverbial relative clause modifier\n",
    "* ccomp: clausal complement\n",
    "* csubj: clausal subject\n",
    "* csubj:outer: outer clause clausal subject\n",
    "* nsubj:outer: outer clause nominal subject\n",
    "* parataxis: parataxis\n",
    "* xcomp: open clausal complement (only for tokens with upos = VERB)\n",
    "* conj: conjunct (only for tokens with upos = VERB)\n",
    "\n",
    "### T-units\n",
    "* root\n",
    "* parataxis\n",
    "* conj between verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b09a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceComplexity:\n",
    "\n",
    "    def __init__(self, tokenlist, tree, verbose=False):\n",
    "        self.tokenlist = tokenlist\n",
    "        self.tree = tree\n",
    "        self.text = tokenlist.metadata['text']\n",
    "        if verbose:\n",
    "            tree.print_tree()\n",
    "\n",
    "        self.length = 0\n",
    "        self.c_heads, self.t_heads, self.np_heads = [], [], []\n",
    "        self.pos_chain, self.dep_chain, self.dep_dists = [], [], []\n",
    "        nodes, nonterminal = [], []\n",
    "\n",
    "        for token in self.tokenlist:\n",
    "            if token['upos'] not in {'PUNCT', 'SYM', '_'}:\n",
    "                self.length += 1\n",
    "                # terminal and non-terminal nodes\n",
    "                nodes.append(token['id'])\n",
    "                nonterminal.append(token['head'])\n",
    "                # pos/deprel chains\n",
    "                self.pos_chain.append(token['upos'])\n",
    "                self.dep_chain.append(token['deprel'])\n",
    "                # dependency distances\n",
    "                self.dep_dists.append(abs(token['head'] - token['id']))\n",
    "                # T-unit extraction\n",
    "                if token['deprel'] in {'root', 'parataxis'} or (token['deprel'] == 'conj' and token['upos'] == 'VERB'):\n",
    "                    self.t_heads.append(token['id'])\n",
    "                    self.c_heads.append(token['id'])\n",
    "                # clause extraction\n",
    "                if token['deprel'] in {'advcl', 'advcl:relcl', 'acl', 'acl:relcl', 'ccomp', 'nsubj:outer', 'csubj:outer', 'csubj'\n",
    "                                       } or (token['deprel'] == 'xcomp' and token['upos'] == 'VERB'):\n",
    "                    self.c_heads.append(token['id'])\n",
    "                # NP extraction\n",
    "                if token['upos'] in {'NOUN', 'PROPN', 'PRON'}:\n",
    "                    self.np_heads.append(token['id'])\n",
    "\n",
    "        self.terminal = set(nodes).difference(nonterminal)\n",
    "        self.nonterminal = set(nonterminal)\n",
    "\n",
    "        # extract clauses    \n",
    "        self.clauses = self.get_clauses()\n",
    "        self.num_cl = len(self.clauses)\n",
    "\n",
    "        # extract t-units    \n",
    "        self.t_units = self.get_tunits()\n",
    "        self.num_tu = len(self.t_units)\n",
    "\n",
    "        # extract NPs\n",
    "        self.nps = self.get_nps()\n",
    "        self.num_np = len(self.nps)\n",
    "\n",
    "        # extract tree depth\n",
    "        self.tree_depth = self.get_tree_depth(self.tree)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def get_tree_depth(self, root):\n",
    "        if not root.children:\n",
    "            return 1\n",
    "        else:\n",
    "            return 1 + max(self.get_tree_depth(child) for child in root.children)\n",
    "\n",
    "    def get_curr_node(self, root, curr_id):\n",
    "        if root.token['id'] == curr_id:\n",
    "            return root\n",
    "        for child in root.children:\n",
    "            curr_id = self.get_curr_node(child, curr_id)\n",
    "        return curr_id\n",
    "\n",
    "    def get_descendants(self, curr_token, heads):\n",
    "        descendants = []\n",
    "        def recurse(curr_token):\n",
    "            for child in curr_token.children:\n",
    "                if child.token['id'] not in heads and child.token['upos'] not in {'_', 'PUNCT', 'SYM'}:\n",
    "                    descendants.append(child.token['id'])\n",
    "                    recurse(child)\n",
    "        recurse(curr_token)\n",
    "        return descendants\n",
    "\n",
    "    def get_noun_descendants(self, curr_token, heads):\n",
    "        descendants = []\n",
    "        def recurse(curr_token):\n",
    "            for child in curr_token.children:\n",
    "                if (child.token['upos'] not in {'_', 'PUNCT', 'SYM'} and child.token['deprel'] in {\n",
    "                        'nmod', 'nmod:poss', 'nmod:tmod', 'appos', 'amod', 'nummod', 'nummod:gov',\n",
    "                        'det', 'case'}):\n",
    "                    descendants.append(child.token['id'])\n",
    "                    recurse(child)\n",
    "        recurse(curr_token)\n",
    "        return descendants\n",
    "\n",
    "    def get_clauses(self):\n",
    "        clauses = []\n",
    "        for head_id in self.c_heads:\n",
    "            head_node = self.get_curr_node(self.tree, head_id)\n",
    "            descendants = [self.tokenlist.filter(id=child_id)[0]\n",
    "                           for child_id in self.get_descendants(head_node, self.c_heads)]\n",
    "            id_to_text = {head_id: head_node.token['form']}\n",
    "            for dep in descendants:\n",
    "                id_to_text[dep['id']] = dep['form']\n",
    "            clause = {'head_id': head_id,\n",
    "                      'head_node': head_node,\n",
    "                      'dep_ids': [dep['id'] for dep in descendants],\n",
    "                      'dep_nodes': descendants,\n",
    "                      'rel_type': head_node.token['deprel'],\n",
    "                      'text': ' '.join(dict(sorted(id_to_text.items())).values())}\n",
    "            clauses.append(clause)\n",
    "        return clauses\n",
    "\n",
    "    def get_tunits(self):\n",
    "        t_units = []\n",
    "        for head_id in self.t_heads:\n",
    "            head_node = self.get_curr_node(self.tree, head_id)\n",
    "            descendants = [self.tokenlist.filter(id=child_id)[0]\n",
    "                           for child_id in self.get_descendants(head_node, self.t_heads)]\n",
    "            id_to_text = {head_id: head_node.token['form']}\n",
    "            for dep in descendants:\n",
    "                id_to_text[dep['id']] = dep['form']\n",
    "            t_unit = {'head_id': head_id,\n",
    "                      'head_node': head_node,\n",
    "                      'dep_ids': [dep['id'] for dep in descendants],\n",
    "                      'dep_nodes': descendants,\n",
    "                      'rel_type': head_node.token['deprel'],\n",
    "                      'text': ' '.join(dict(sorted(id_to_text.items())).values())}\n",
    "            t_units.append(t_unit)\n",
    "        return t_units\n",
    "\n",
    "    def get_nps(self):\n",
    "        nps = []\n",
    "        all_descendants = []\n",
    "        for head_id in self.np_heads:\n",
    "            head_node = self.get_curr_node(self.tree, head_id)\n",
    "            descendants = [self.tokenlist.filter(id=child_id)[0]\n",
    "                           for child_id in self.get_noun_descendants(head_node, self.t_heads)]\n",
    "            if head_id in all_descendants:\n",
    "                continue\n",
    "            all_descendants.extend([dep['id'] for dep in descendants])\n",
    "            id_to_text = {head_id: head_node.token['form']}\n",
    "            for dep in descendants:\n",
    "                id_to_text[dep['id']] = dep['form']\n",
    "            np = {'head_id': head_id,\n",
    "                  'head_node': head_node,\n",
    "                  'dep_ids': [dep['id'] for dep in descendants],\n",
    "                  'dep_nodes': descendants,\n",
    "                  'rel_type': head_node.token['deprel'],\n",
    "                  'length': len(id_to_text),\n",
    "                  'text': ' '.join(dict(sorted(id_to_text.items())).values())}\n",
    "            nps.append(np)\n",
    "        return nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc14b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['annotated'].tolist()[0]\n",
    "\n",
    "sentences = parse(text)\n",
    "trees = parse_tree(text)\n",
    "\n",
    "sent = sentences[0]\n",
    "tree = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24cdacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(deprel:root) form:запомнилось lemma:запомниться upos:VERB [12]\n",
      "    (deprel:advcl) form:Прокатившись lemma:прокатиться upos:VERB [1]\n",
      "        (deprel:obl) form:городам lemma:город upos:NOUN [4]\n",
      "            (deprel:case) form:по lemma:по upos:ADP [2]\n",
      "            (deprel:amod) form:многим lemma:много upos:NUM [3]\n",
      "            (deprel:conj) form:странам lemma:страна upos:NOUN [6]\n",
      "                (deprel:cc) form:и lemma:и upos:CCONJ [5]\n",
      "        (deprel:obl) form:лет lemma:год upos:NOUN [10]\n",
      "            (deprel:case) form:за lemma:за upos:ADP [7]\n",
      "            (deprel:nummod) form:несколько lemma:несколько upos:NUM [9]\n",
      "                (deprel:amod) form:последние lemma:последний upos:ADJ [8]\n",
      "        (deprel:punct) form:, lemma:, upos:PUNCT [11]\n",
      "    (deprel:nsubj) form:количество lemma:количество upos:NOUN [14]\n",
      "        (deprel:amod) form:большое lemma:большой upos:ADJ [13]\n",
      "        (deprel:nmod) form:мест lemma:место upos:NOUN [16]\n",
      "            (deprel:amod) form:интереснейших lemma:интересный upos:ADJ [15]\n",
      "            (deprel:nmod) form:которых lemma:который upos:PRON [18]\n",
      "                (deprel:case) form:из lemma:из upos:ADP [17]\n",
      "        (deprel:acl:relcl) form:хотелось lemma:хотеться upos:VERB [21]\n",
      "            (deprel:advmod) form:страшно lemma:страшно upos:ADV [19]\n",
      "            (deprel:advmod) form:не lemma:не upos:PART [20]\n",
      "            (deprel:xcomp) form:уезжать lemma:уезжать upos:VERB [22]\n",
      "    (deprel:punct) form:. lemma:. upos:PUNCT [23]\n"
     ]
    }
   ],
   "source": [
    "ex = SentenceComplexity(sent, tree, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be87ac8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Прокатившись по многим городам и странам за последние несколько лет',\n",
       " 'запомнилось большое количество интереснейших мест из которых',\n",
       " 'страшно не хотелось',\n",
       " 'уезжать']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[clause['text'] for clause in ex.clauses]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5526386",
   "metadata": {},
   "source": [
    "## Whole text complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "529cca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextComplexity:\n",
    "\n",
    "    def __init__(self, annotation, verbose=False):\n",
    "\n",
    "        if isinstance(annotation, str):\n",
    "            self.sentences = parse(annotation)\n",
    "            self.trees = [sent.to_tree() for sent in self.sentences]\n",
    "        elif isinstance(annotation, conllu.models.SentenceList):\n",
    "            self.sentences = annotation\n",
    "            self.trees = [sent.to_tree() for sent in annotation]\n",
    "        else:\n",
    "            raise TypeError('Input must be either a string in CoNLL-U format ' +\n",
    "                            'or a conllu.models.SentenceList!')\n",
    "\n",
    "        # initialize SentenceComplexity instances\n",
    "        self.sent_comp = []\n",
    "        self.num_w, self.num_cl, self.num_tu = 0, 0, 0\n",
    "        self.pos_chains, self.dep_chains, self.tree_depths = [], [], []\n",
    "        dep_dists, terminal, nonterminal, nps = [], [], [], []\n",
    "        self.clause_counter = dict.fromkeys(['root', 'acl', 'acl:relcl', 'advcl', 'advcl:relcl',\n",
    "                                             'ccomp', 'csubj', 'csubj:outer', 'nsubj:outer',\n",
    "                                             'parataxis', 'xcomp', 'conj'], 0)\n",
    "\n",
    "        for i, sent in enumerate(self.sentences):\n",
    "            sent = SentenceComplexity(sent, self.trees[i])\n",
    "            self.sent_comp.append(sent)\n",
    "            if len(sent) == 0:  # exclude broken sentences\n",
    "                continue\n",
    "            self.num_w += len(sent)  # number of words\n",
    "            dep_dists.extend(sent.dep_dists)  # dependency distances\n",
    "            terminal.extend(sent.terminal)  # terminal nodes\n",
    "            nonterminal.extend(sent.nonterminal)  # nonterminal nodes\n",
    "            nps.extend(sent.nps)  # noun phrases\n",
    "            self.num_cl += sent.num_cl\n",
    "            self.num_tu += sent.num_tu\n",
    "            self.pos_chains.append(sent.pos_chain)\n",
    "            self.dep_chains.append(sent.dep_chain)\n",
    "            self.tree_depths.append(sent.tree_depth)\n",
    "            for clause in sent.clauses:\n",
    "                self.clause_counter[clause['rel_type']] += 1\n",
    "\n",
    "        if self.num_w == 0:\n",
    "            raise ValueError('The annotation is empty!')\n",
    "        self.num_s = len(self.sent_comp)  # number of sentences\n",
    "\n",
    "        self.msl = self.num_w / self.num_s  # mean sentence length\n",
    "        self.mcl = self.num_w / self.num_cl  # mean clause length\n",
    "        self.mtl = self.num_w / self.num_tu  # mean t-unit length\n",
    "\n",
    "        self.cps = self.num_cl / self.num_s  # clauses per sentence\n",
    "        self.cpt = self.num_cl / self.num_tu  # clauses per T-unit\n",
    "\n",
    "        try:\n",
    "            self.lev_pos = mean(self.pairwise_levenshtein(self.pos_chains))  # avg Levenshtein distance for POS\n",
    "            self.lev_dep = mean(self.pairwise_levenshtein(self.dep_chains))  # avg Levenshtein distance for deprel\n",
    "        except StatisticsError:\n",
    "            self.lev_pos, self.lev_dep = 0, 0\n",
    "\n",
    "        self.mtd = mean(self.tree_depths)  # mean tree depth\n",
    "        self.mdtd = median(self.tree_depths)  # median tree depth\n",
    "        self.mxtd = max(self.tree_depths)  # max tree depth\n",
    "        self.mntd = min(self.tree_depths)  # min tree depth\n",
    "\n",
    "        self.mdd = mean(dep_dists)  # mean dependency distance\n",
    "        self.node_to_term = len(nonterminal) / len(terminal)  # node to terminal node ratio\n",
    "\n",
    "        # clausal measures\n",
    "        self.clause_counter = {rel: num / self.num_cl for rel, num in self.clause_counter.items()}\n",
    "        self.comb = self.num_cl - self.num_s  # combined clauses  !!! НЕВЕРНО (исправлено ниже)\n",
    "        self.coord = self.clause_counter['conj'] + self.clause_counter['parataxis']\n",
    "        self.subord = self.comb - self.coord\n",
    "\n",
    "        try:\n",
    "            self.coord_to_comb = self.coord / self.comb  # coordinate to combined clause ratio\n",
    "        except ZeroDivisionError:\n",
    "            self.coord_to_comb = 0\n",
    "\n",
    "        try:\n",
    "            self.subord_to_comb = self.subord / self.comb  # coordinate to combined clause ratio\n",
    "        except ZeroDivisionError:\n",
    "            self.subord_to_comb = 0\n",
    "\n",
    "        self.coord_to_sent = self.coord / self.num_s  # coordinate clause to sentence ratio\n",
    "        self.subord_to_sent = self.subord / self.num_s  # subordinate clause to sentence ratio\n",
    "\n",
    "        self.avg_np_len = mean([np['length'] for np in nps])  # average NP length\n",
    "        self.comp_np_ratio = len([np for np in nps if np['length'] > 1]) / len(nps)  # complex NPs per clause\n",
    "\n",
    "    def pairwise_levenshtein(self, chains):\n",
    "        return [levenshtein.distance(a, b) for a, b in combinations(chains, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035eb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = TextComplexity(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8c1618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.583333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.mtd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c519b",
   "metadata": {},
   "source": [
    "## Calculate measures for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "026e7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['annotated'].tolist()\n",
    "comp_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dceac24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437983bb9186470d85a0efd3ca3f95f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, text in tqdm(enumerate(texts), total=len(texts)):\n",
    "    if i in comp_dict:\n",
    "        continue\n",
    "    try:\n",
    "        comp_dict[i] = TextComplexity(text)\n",
    "    except (ValueError, ParseException):\n",
    "        comp_dict[i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ba1c09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49397"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d9fafe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49397, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>language</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>language_background</th>\n",
       "      <th>text</th>\n",
       "      <th>spell_checked</th>\n",
       "      <th>annotated</th>\n",
       "      <th>mark</th>\n",
       "      <th>level</th>\n",
       "      <th>text_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actr</td>\n",
       "      <td>russian</td>\n",
       "      <td>L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Прокатившись по многим городам и странам за по...</td>\n",
       "      <td>Прокатившись по многим городам и странам за по...</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heritage 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actr</td>\n",
       "      <td>russian</td>\n",
       "      <td>L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>В моей жизни я встречала много разных людей. У...</td>\n",
       "      <td>В моей жизни я встречала много разных людей. У...</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heritage 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actr</td>\n",
       "      <td>russian</td>\n",
       "      <td>L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>В прошлем году, я провела четыре месяцев в Лон...</td>\n",
       "      <td>В прошлом году, я провела четыре месяцев в Лон...</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heritage 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus language speaker_type language_background  \\\n",
       "0   actr  russian           L1                 NaN   \n",
       "1   actr  russian           L1                 NaN   \n",
       "2   actr  russian           L1                 NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0  Прокатившись по многим городам и странам за по...   \n",
       "1  В моей жизни я встречала много разных людей. У...   \n",
       "2  В прошлем году, я провела четыре месяцев в Лон...   \n",
       "\n",
       "                                       spell_checked  \\\n",
       "0  Прокатившись по многим городам и странам за по...   \n",
       "1  В моей жизни я встречала много разных людей. У...   \n",
       "2  В прошлом году, я провела четыре месяцев в Лон...   \n",
       "\n",
       "                                           annotated  mark       level  \\\n",
       "0  # generator = UDPipe 2, https://lindat.mff.cun...   NaN  Heritage 1   \n",
       "1  # generator = UDPipe 2, https://lindat.mff.cun...   NaN  Heritage 1   \n",
       "2  # generator = UDPipe 2, https://lindat.mff.cun...   NaN  Heritage 1   \n",
       "\n",
       "  text_type  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[['corpus', 'language', 'speaker_type', 'language_background',\n",
    "           'text', 'spell_checked', 'annotated', 'mark', 'level', 'text_type']]\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ada62c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329cdc4512f743ee8fb3462bc95e1fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recs = df.to_dict(orient='records')\n",
    "\n",
    "for i, rec in tqdm(enumerate(recs)):\n",
    "    text = comp_dict[i]\n",
    "    if pd.isnull(text):\n",
    "        continue\n",
    "\n",
    "    rec['comp_object'] = text\n",
    "\n",
    "    rec['num_s'] = text.num_s\n",
    "    rec['num_w'] = text.num_w\n",
    "    rec['num_cl'] = text.num_cl\n",
    "    rec['num_tu'] = text.num_tu\n",
    "\n",
    "    rec['msl'] = text.msl\n",
    "    rec['mcl'] = text.num_w / text.num_cl\n",
    "    rec['mtl'] = text.num_w / text.num_tu\n",
    "    rec['cps'] = text.cps\n",
    "    rec['cpt'] = text.cpt\n",
    "\n",
    "    rec['lev_pos'] = text.lev_pos\n",
    "    rec['lev_dep'] = text.lev_dep\n",
    "\n",
    "    rec['mtd'] = text.mtd\n",
    "    rec['mdtd'] = text.mdtd\n",
    "    rec['mxtd'] = text.mxtd\n",
    "    rec['mntd'] = text.mntd\n",
    "\n",
    "    rec['mdd'] = text.mdd\n",
    "    rec['node_to_term'] = text.node_to_term\n",
    "\n",
    "    rec['pos_chains'] = text.pos_chains\n",
    "    rec['dep_chains'] = text.dep_chains\n",
    "    rec['tree_depth'] = text.tree_depths\n",
    "\n",
    "    # coordination/subordination measures\n",
    "    rec['clause_percentage'] = text.clause_counter\n",
    "    rec['clause_counter'] = {key: val * text.num_cl for key, val in text.clause_counter.items()}\n",
    "    rec['comb'] = text.comb\n",
    "    rec['coord'] = rec['clause_counter']['conj'] + rec['clause_counter']['parataxis']\n",
    "    rec['subord'] = text.comb - rec['coord']\n",
    "\n",
    "    try:\n",
    "        rec['coord_to_comb'] = rec['coord'] / rec['comb']\n",
    "    except ZeroDivisionError:\n",
    "        rec['coord_to_comb'] = 0\n",
    "    try:\n",
    "        rec['subord_to_comb'] = rec['subord'] / rec['comb']\n",
    "    except ZeroDivisionError:\n",
    "        rec['subord_to_comb'] = 0\n",
    "    try:\n",
    "        rec['coord_to_subord'] = rec['coord'] / rec['subord']\n",
    "    except ZeroDivisionError:\n",
    "        rec['coord_to_subord'] = 0\n",
    "    rec['coord_to_sent'] = rec['coord'] / rec['num_s']\n",
    "    rec['subord_to_sent'] = rec['subord'] / rec['num_s']\n",
    "\n",
    "    # phrasal measures\n",
    "    rec['avg_np_len'] = text.avg_np_len\n",
    "    rec['comp_np_ratio'] = text.comp_np_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453926b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(recs)\n",
    "df.dropna(subset=['comp_object'], inplace=True)\n",
    "temp = df.drop(columns=['comp_object'])\n",
    "temp.to_csv('CompMeasures.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
